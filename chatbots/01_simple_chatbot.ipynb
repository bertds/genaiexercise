{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc96dc43-8bbf-4d82-9010-34b802ae4798",
   "metadata": {},
   "source": [
    "# Conversational Interface - Chatbot with Strands SDK\n",
    "In this notebook, we will build a chatbot using the Strands SDK and Amazon Bedrock Foundation Models. We use Amazon Nova Lite as our Foundation Model (FM) and implement conversation history management with Strands Agent.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Conversational interfaces such as chatbots and virtual assistants can significantly enhance customer user experience. Modern chatbots leverage Large Language Models (LLMs) built on transformer architecture to understand context and generate human-like responses to user queries. This implementation uses the Strands SDK for simplified agent creation with LLMs on Amazon Bedrock, and includes a Streamlit demo interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9e2e43-c77c-4c8e-a581-f43bfd89fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80151c5c-d919-46d2-83d3-c52d0c550bf5",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0761cfa-a2c2-4d52-be5a-dddae776a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab232464e6db452f957674dec1f45577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Model:', layout=Layout(width='600px'), options=(('Nova Lite - Fast, cost-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Select your preferred model above and run the cells below to see it in action!\n"
     ]
    }
   ],
   "source": [
    "boto3_session = boto3.session.Session()\n",
    "region = boto3_session.region_name\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from util.model_selector import create_text_model_selector\n",
    "\n",
    "# Create interactive model selector\n",
    "model_selector = create_text_model_selector().display()\n",
    "\n",
    "print(\"\\nðŸŽ¯ Select your preferred model above and run the cells below to see it in action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b7041-c816-4764-8672-4b7057e7e705",
   "metadata": {},
   "source": [
    "### Run the chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc34ff-0ee1-4fd2-abff-d00edc0586b0",
   "metadata": {},
   "source": [
    "Set up parameters for the model and create a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb59de4-fcdf-4cfd-b243-2f16da715516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: Nova Lite (us.amazon.nova-lite-v1:0)\n",
      "Description: Fast, cost-effective text generation\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the selected model\n",
    "selected_model = model_selector.get_model_id()\n",
    "model_info = model_selector.get_model_info()\n",
    "\n",
    "print(f\"Using model: {model_info['name']} ({selected_model})\")\n",
    "print(f\"Description: {model_info['description']}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "temperature = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28852f4f-d7e1-49a8-959b-1a8eb8e8083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bedrock model with Strands SDK\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=selected_model,\n",
    "    temperature=temperature,\n",
    "    #region=region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cdcab-ce24-4fb0-ba5f-cd4359690fdc",
   "metadata": {},
   "source": [
    "The Strands Agent automatically maintains conversation history in memory during runtime, providing context across multiple interactions within a single session. For production deployments with distributed architectures or to preserve conversations across application restarts, Strands offers built-in persistence options through session managers like FileSessionManager and S3SessionManager. You can also implement custom persistence solutions using the SessionManager interface and a key-value store such as Amazon DynamoDB which enables scalable context management across distributed systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18901bf2-b71f-4941-9a39-f53d05d0ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple chatbot agent\n",
    "chatbot_agent = Agent(\n",
    "    system_prompt=\"You are a helpful assistant. Maintain conversation context and remember what users tell you.\",\n",
    "    model=bedrock_model,\n",
    "    callback_handler=None,  # default is PrintingCallbackHandler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4bb8438-b0b0-42a3-aacd-53d1fa316d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Bob! It's nice to meet you. How can I assist you today? If you have any questions or need help with something, feel free to let me know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the chatbot\n",
    "response = chatbot_agent(\"hi - i am bob!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60275cab-a8d8-470a-bfa3-8b78636d28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Bob, as you mentioned earlier. If you ever need a reminder or have any other questions, feel free to ask! How can I assist you today, Bob?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test conversation memory\n",
    "response = chatbot_agent(\"whats my name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c975f46-0e2a-4823-bdd9-be2a8ec9ce9d",
   "metadata": {},
   "source": [
    "For quick prototyping and development, you can leverage Strands Agent's built-in memory capabilities without any configuration, allowing you to focus on agent logic while conversation context is managed automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8ebfd-92bc-4ac7-b537-9510a8b0f2bc",
   "metadata": {},
   "source": [
    "### Create a Multi-Lingual Greeter Chatbot!\n",
    "With Strands SDK, we can easily create specialized agents with custom system prompts. Let's create a multi-lingual translator agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5151501-1ec6-4400-9cf8-82194d0836e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, je m'appelle John. Comment puis-je vous aider aujourd'hui ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a multi-lingual translator agent\n",
    "translator_agent = Agent(\n",
    "    system_prompt=\"You're an assistant who speaks in French. Translate user input to French and maintain conversation context.\",\n",
    "    model=bedrock_model,\n",
    "    callback_handler=None,  # default is PrintingCallbackHandler\n",
    ")\n",
    "\n",
    "response = translator_agent(\"Hi my name is John\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2288d1-4dc8-4de2-8e3a-a421bf40a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votre nom est John. Y a-t-il autre chose que vous aimeriez discuter ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = translator_agent(\"What is my name?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streamlit-demo",
   "metadata": {},
   "source": [
    "## Streamlit Demo\n",
    "\n",
    "Now let's create an interactive web interface using the chatbot code you've built above!\n",
    "\n",
    "### Step 1: Add Your Code\n",
    "\n",
    "1. Open `chatbot_demo.py`\n",
    "2. Copy the bedrock model initialization and agent creation code similar to that above:\n",
    "   ```python\n",
    "    boto3_session = boto3.session.Session()\n",
    "    region = boto3_session.region_name or \"us-east-1\"\n",
    "    \n",
    "    bedrock_model = BedrockModel(\n",
    "        model_id=st.session_state.current_model,\n",
    "        temperature=temperature,\n",
    "        region=region\n",
    "    )\n",
    "\n",
    "    st.session_state.agent = Agent(\n",
    "        system_prompt=\"You are a helpful AI assistant. Be conversational and maintain context throughout our chat.\",\n",
    "        model=bedrock_model\n",
    "    )\n",
    "   ```\n",
    "3. Paste the code into the designated section marked `# PASTE YOUR CODE HERE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc10976",
   "metadata": {},
   "source": [
    "### Step 2: Run the Demo\n",
    "\n",
    "1. Open a terminal\n",
    "2. Change the directory to where the `chatbot_demo.py` file is:\n",
    "\n",
    "    ```\n",
    "    cd /workshop/chatbots\n",
    "    ```\n",
    "3. Run the script with streamlit:\n",
    "\n",
    "    ```bash\n",
    "    streamlit run chatbot_demo.py\n",
    "    ```\n",
    "4. You will see an output like:\n",
    "\n",
    "    ```\n",
    "    You can now view your Streamlit app in your browser.\n",
    "\n",
    "    Local URL: http://localhost:8501\n",
    "    ```\n",
    "5. Go to the ports tab and open the Amazon CloudFront URL next to the port (here 8501) to access the streamlit application:\n",
    "\n",
    "    ![The **Ports** tab in the Code Editor shows URLs to ports running on the remote server](./images/forwarded_port.png)\n",
    "\n",
    "The web interface includes:\n",
    "- Model selection\n",
    "- Temperature control\n",
    "- Chat history with automatic context preservation\n",
    "- Clear chat functionality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
