{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f5e13a",
   "metadata": {},
   "source": [
    "# Text Generation with Amazon Bedrock\n",
    "\n",
    "> *This notebook should work well with the **`Python 3`** kernel from **`SageMaker Distribution 2.1`** in SageMaker Studio*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, you will explore different capabilities of Amazon Bedrock and how to use foundation models for the following use cases:\n",
    "\n",
    "1. **Text Summarization**: Create concise summaries from longer text passages\n",
    "2. **Code Generation**: Generate Python and SQL code from natural language descriptions\n",
    "3. **Entity Extraction**: Extract structured information from unstructured text\n",
    "\n",
    "You'll see how to use the unified Converse API to interact with different foundation models available through Amazon Bedrock, focusing primarily on the Amazon Nova family of models.\n",
    "\n",
    "### Prerequisites\n",
    "- Access to Amazon Bedrock\n",
    "- Appropriate IAM permissions\n",
    "- Python 3.x environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae8d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253917be411a41bca8e69b46e65df9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Model:', layout=Layout(width='600px'), options=(('Nova Lite - Fast, cost-‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Select your preferred model above and run the cells below to see it in action!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from util.model_selector import create_text_model_selector, bedrock, create_messages\n",
    "\n",
    "# Create interactive model selector\n",
    "model_selector = create_text_model_selector().display()\n",
    "\n",
    "print(\"\\nüéØ Select your preferred model above and run the cells below to see it in action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9883d67",
   "metadata": {},
   "source": [
    "## 1. Text Summarization: Create concise summaries from longer text passages\n",
    "\n",
    "To learn the details of API requests to Amazon Bedrock, this notebook introduces how to use the unified Converse API which works consistently across all models, eliminating the need for model-specific formatting.\n",
    "\n",
    "### Unified Converse API Benefits\n",
    "\n",
    "The Converse API provides:\n",
    "- **Consistent Interface**: Same API works for all text models (Nova, Claude, Titan, etc.)\n",
    "- **Standardized Parameters**: Unified inference configuration\n",
    "- **Simplified Integration**: No need for model-specific body formatting\n",
    "- **Future Proof**: New models work automatically without code changes\n",
    "\n",
    "### Writing prompt with text to be summarized\n",
    "\n",
    "In this notebook, you can use any short text whose tokens are less than the maximum token of a foundation model. As an example of short text, let's take one paragraph of an [AWS blog post](https://aws.amazon.com/jp/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) about announcement of Amazon Bedrock.\n",
    "\n",
    "The prompt starts with an instruction `Please provide a summary of the following text.`, and includes text surrounded by `<text>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fea20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please provide a summary of the following text. Do not add any information that is not mentioned in the text below.\n",
    "\n",
    "<text>\n",
    "AWS took all of that feedback from customers, and today we are excited to announce Amazon Bedrock, \\\n",
    "a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. \\\n",
    "Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, \\\n",
    "democratizing access for all builders. Bedrock will offer the ability to access a range of powerful FMs \\\n",
    "for text and images‚Äîincluding Amazons Titan FMs, which consist of two new LLMs we're also announcing \\\n",
    "today‚Äîthrough a scalable, reliable, and secure AWS managed service. With Bedrock's serverless experience, \\\n",
    "customers can easily find the right model for what they're trying to get done, get started quickly, privately \\\n",
    "customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS \\\n",
    "tools and capabilities they are familiar with, without having to manage any infrastructure (including integrations \\\n",
    "with Amazon SageMaker ML features like Experiments to test different models and Pipelines to manage their FMs at scale).\n",
    "</text>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96dc786",
   "metadata": {},
   "source": [
    "### Invoke foundation model via Unified Converse API\n",
    "\n",
    "This section demonstrates how to send API requests to Amazon Bedrock using the unified Converse API. The beauty of this approach is that the same code works with any text model - you just change the model selection above!\n",
    "\n",
    "The foundation model will process the input based on the provided prompt and model-specific configuration parameters. In the following example, the foundation model in Amazon Bedrock summarizes the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b929568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: Nova Pro (us.amazon.nova-pro-v1:0)\n",
      "Description: Advanced reasoning and complex tasks\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sending messages:\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"text\": \"\\nPlease provide a summary of the following text. Do not add any information that is not mentioned in the text below.\\n\\n<text>\\nAWS took all of that feedback from customers, and today we are excited to announce Amazon Bedrock, a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. Bedrock will offer the ability to access a range of powerful FMs for text and images\\u2014including Amazons Titan FMs, which consist of two new LLMs we're also announcing today\\u2014through a scalable, reliable, and secure AWS managed service. With Bedrock's serverless experience, customers can easily find the right model for what they're trying to get done, get started quickly, privately customize FMs with their own data, and easily integrate and deploy them into their applications using the AWS tools and capabilities they are familiar with, without having to manage any infrastructure (including integrations with Amazon SageMaker ML features like Experiments to test different models and Pipelines to manage their FMs at scale).\\n</text>\\n\\n\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "üìù Summary:\n",
      "AWS has introduced Amazon Bedrock, a new service based on customer feedback. Bedrock provides access to Foundation Models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon through an API. It aims to simplify the building and scaling of generative AI applications using FMs, making it accessible for all developers. Bedrock offers a variety of powerful FMs for text and images, including Amazon's newly announced Titan FMs, which consist of two Large Language Models (LLMs). It is a scalable, reliable, and secure AWS managed service. Bedrock's serverless experience allows customers to easily select the appropriate model, start quickly, customize FMs with their own data, and integrate and deploy them into applications using familiar AWS tools and capabilities. Infrastructure management, including integration with Amazon SageMaker ML features like Experiments and Pipelines, is handled by AWS.\n"
     ]
    }
   ],
   "source": [
    "# Get the selected model\n",
    "selected_model = model_selector.get_model_id()\n",
    "model_info = model_selector.get_model_info()\n",
    "\n",
    "print(f\"Using model: {model_info['name']} ({selected_model})\")\n",
    "print(f\"Description: {model_info['description']}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Create messages using our helper function\n",
    "messages = create_messages(prompt)\n",
    "\n",
    "print(f\"Sending messages:\\n{json.dumps(messages, indent=4)}\")\n",
    "\n",
    "# Invoke the model using unified API\n",
    "try:\n",
    "    response = bedrock.converse(\n",
    "        model_id=selected_model,\n",
    "        messages=messages,\n",
    "        max_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    if response:\n",
    "        print(\"üìù Summary:\")\n",
    "        print(response)\n",
    "    else:\n",
    "        print(\"‚ùå Failed to generate response\")\n",
    "        \n",
    "except Exception as error:\n",
    "    print(f\"‚ùå Error: {str(error)}\")\n",
    "    print(\"\\nTo troubleshoot this issue please refer to the following resources:\")\n",
    "    print(\"https://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\")\n",
    "    print(\"https://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128f74e",
   "metadata": {},
   "source": [
    "AWS has introduced Amazon Bedrock, a new service based on customer feedback. Bedrock provides access to Foundation Models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon through an API. It aims to simplify the building and scaling of generative AI applications using FMs, making it accessible for all developers. Bedrock offers a variety of powerful FMs for text and images, including Amazon's newly announced Titan FMs, which consist of two Large Language Models (LLMs). It is a scalable, reliable, and secure AWS managed service. Bedrock's serverless experience allows customers to easily select the appropriate model, start quickly, customize FMs with their own data, and integrate and deploy them into applications using familiar AWS tools and capabilities. Infrastructure management, including integration with Amazon SageMaker ML features like Experiments and Pipelines, is handled by AWS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9f2382",
   "metadata": {},
   "source": [
    "AWS has introduced Amazon Bedrock, a new service based on customer feedback. Bedrock provides access to Foundation Models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon through an API. It aims to simplify the building and scaling of generative AI applications using FMs, making it accessible for all developers. The service offers a variety of powerful FMs for text and images, including Amazon's newly announced Titan FMs, which consist of two Large Language Models (LLMs). Bedrock is a scalable, reliable, and secure AWS-managed service. It features a serverless experience allowing customers to easily select appropriate models, start quickly, customize FMs with private data, and integrate and deploy them using familiar AWS tools without managing infrastructure. It also supports integration with Amazon SageMaker ML features like Experiments for testing models and Pipelines for managing FMs at scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd27bc",
   "metadata": {},
   "source": [
    "AWS has introduced Amazon Bedrock, a new service that provides access to Foundation Models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon via an API. Bedrock aims to simplify the process of building and scaling generative AI-based applications using FMs, making it accessible to all developers. The service offers a range of powerful FMs for text and images, including Amazon's Titan FMs, through a scalable, reliable, and secure AWS managed service. Bedrock's serverless experience allows customers to find suitable models, start quickly, customize FMs with their data, and integrate and deploy them into applications using familiar AWS tools and capabilities, without managing any infrastructure. It also integrates with Amazon SageMaker ML features like Experiments and Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c7e59",
   "metadata": {},
   "source": [
    "### Compare Different Models\n",
    "\n",
    "The beauty of our unified system is that you can easily compare different models by simply changing the selection above and re-running the cell. Try selecting different models to see how they perform on the same task!\n",
    "\n",
    "### Conclusion on Text Summarization\n",
    "\n",
    "You have now experimented with using the unified Converse API which provides a consistent interface across all Amazon Bedrock models. Using this API you have seen the use case of generating a summary of AWS news about Amazon Bedrock.\n",
    "\n",
    "### Additional challenges\n",
    "\n",
    "- Experiment with different models using the dropdown selector above\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models\n",
    "- Play with the token length to understand the latency and responsiveness of the service\n",
    "- Apply different prompt engineering principles to get better outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b52b36a",
   "metadata": {},
   "source": [
    "## 2. Code Generation: Generate Python and SQL code from natural language descriptions\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this section we show you how to use a LLM to generate code based on the text prompt. We will use the unified Converse API that works with any model you select.\n",
    "\n",
    "The prompt used in this example is called a zero-shot prompt because we are not providing any examples of text other than the prompt.\n",
    "\n",
    "**Note:** *This notebook can be run within or outside of AWS environment.*\n",
    "\n",
    "##### Context\n",
    "To demonstrate the code generation capability of Amazon Bedrock, we will explore the use of the unified Converse API. We will demonstrate different configurations available as well as how simple input can lead to desired outputs. We will explore code generation for two use cases:\n",
    "\n",
    "1. Python code generation for analytical QnA\n",
    "2. SQL query generation\n",
    "\n",
    "##### Pattern\n",
    "\n",
    "In both use cases, we will simply provide the Amazon Bedrock API with an input consisting of a task, an instruction and an input for the model under the hood to generate an output without providing any additional example. The purpose here is to demonstrate how the powerful LLMs easily understand the task at hand and generate compelling outputs.\n",
    "\n",
    "### Use case 1 - Python code generation for Analytical QnA\n",
    "\n",
    "To demonstrate the generation capability of models in Amazon Bedrock, let's take the use case of code generation with Python to do some basic analytical QnA.\n",
    "\n",
    "##### Persona\n",
    "\n",
    "You are Moe, a Data Analyst, at AnyCompany. The company wants to understand its sales performance for different products over the past year. You have been provided a dataset named sales.csv. The dataset contains the following columns:\n",
    "\n",
    "- Date (YYYY-MM-DD) format\n",
    "- Product_ID (unique identifier for each product)\n",
    "- Price (price at which each product was sold)\n",
    "\n",
    "##### Implementation\n",
    "\n",
    "To fulfill this use case, in this notebook we will show how to generate code for a given prompt using our unified model selection system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde814a",
   "metadata": {},
   "source": [
    "#### Lab setup - create sample sales.csv data for this lab.\n",
    "\n",
    "Following on the use case explained above, let's prepare an input for the Amazon Bedrock service to generate python program for our use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf09f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales.csv has been created!\n"
     ]
    }
   ],
   "source": [
    "# create sales.csv file\n",
    "import csv\n",
    "\n",
    "data = [\n",
    "    [\"date\", \"product_id\", \"price\", \"units_sold\"],\n",
    "    [\"2023-01-01\", \"P001\", 50, 20],\n",
    "    [\"2023-01-02\", \"P002\", 60, 15],\n",
    "    [\"2023-01-03\", \"P001\", 50, 18],\n",
    "    [\"2023-01-04\", \"P003\", 70, 30],\n",
    "    [\"2023-01-05\", \"P001\", 50, 25],\n",
    "    [\"2023-01-06\", \"P002\", 60, 22],\n",
    "    [\"2023-01-07\", \"P003\", 70, 24],\n",
    "    [\"2023-01-08\", \"P001\", 50, 28],\n",
    "    [\"2023-01-09\", \"P002\", 60, 17],\n",
    "    [\"2023-01-10\", \"P003\", 70, 29],\n",
    "    [\"2023-02-11\", \"P001\", 50, 23],\n",
    "    [\"2023-02-12\", \"P002\", 60, 19],\n",
    "    [\"2023-02-13\", \"P001\", 50, 21],\n",
    "    [\"2023-02-14\", \"P003\", 70, 31],\n",
    "    [\"2023-03-15\", \"P001\", 50, 26],\n",
    "    [\"2023-03-16\", \"P002\", 60, 20],\n",
    "    [\"2023-03-17\", \"P003\", 70, 33],\n",
    "    [\"2023-04-18\", \"P001\", 50, 27],\n",
    "    [\"2023-04-19\", \"P002\", 60, 18],\n",
    "    [\"2023-04-20\", \"P003\", 70, 32],\n",
    "    [\"2023-04-21\", \"P001\", 50, 22],\n",
    "    [\"2023-04-22\", \"P002\", 60, 16],\n",
    "    [\"2023-04-23\", \"P003\", 70, 34],\n",
    "    [\"2023-05-24\", \"P001\", 50, 24],\n",
    "    [\"2023-05-25\", \"P002\", 60, 21]\n",
    "]\n",
    "\n",
    "# Write data to sales.csv\n",
    "with open('sales.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"sales.csv has been created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e09e97",
   "metadata": {},
   "source": [
    "#### Analyzing sales with Amazon Bedrock generated Python program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51064c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt for code generation\n",
    "prompt_data = \"\"\"\n",
    "You have a CSV, sales.csv, with columns:\n",
    "- date (YYYY-MM-DD)\n",
    "- product_id\n",
    "- price\n",
    "- units_sold\n",
    "\n",
    "Create a python program to analyze the sales data from a CSV file. The program should be able to read the data, and determine below:\n",
    "\n",
    "- Total revenue for the year\n",
    "- The product with the highest revenue\n",
    "- The date with the highest revenue\n",
    "- Visualize monthly sales using a bar chart\n",
    "\n",
    "Ensure the code is syntactically correct, bug-free, optimized, not span multiple lines unnecessarily, and prefer to use standard libraries. Return only python code without any surrounding text, explanation or context.\n",
    "Do not use pandas library for the solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6df7fb",
   "metadata": {},
   "source": [
    "Generate the code using the selected model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2465e67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Generating Python code using: Nova Pro\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìã Generated Python Code:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "```python\n",
       "import csv\n",
       "from collections import defaultdict\n",
       "import matplotlib.pyplot as plt\n",
       "from datetime import datetime\n",
       "\n",
       "def analyze_sales(file_path):\n",
       "    with open(file_path, newline='') as csvfile:\n",
       "        reader = csv.DictReader(csvfile)\n",
       "        data = [row for row in reader]\n",
       "\n",
       "    total_revenue = sum(float(row['price']) * int(row['units_sold']) for row in data)\n",
       "    \n",
       "    product_revenue = defaultdict(float)\n",
       "    date_revenue = defaultdict(float)\n",
       "    monthly_sales = defaultdict(float)\n",
       "\n",
       "    for row in data:\n",
       "        revenue = float(row['price']) * int(row['units_sold'])\n",
       "        product_revenue[row['product_id']] += revenue\n",
       "        date_revenue[row['date']] += revenue\n",
       "        month = datetime.strptime(row['date'], '%Y-%m-%d').strftime('%Y-%m')\n",
       "        monthly_sales[month] += revenue\n",
       "\n",
       "    top_product = max(product_revenue, key=product_revenue.get)\n",
       "    top_date = max(date_revenue, key=date_revenue.get)\n",
       "\n",
       "    months = sorted(monthly_sales.keys())\n",
       "    sales = [monthly_sales[month] for month in months]\n",
       "\n",
       "    plt.bar(months, sales)\n",
       "    plt.xlabel('Month')\n",
       "    plt.ylabel('Sales')\n",
       "    plt.title('Monthly Sales')\n",
       "    plt.xticks(rotation=45)\n",
       "    plt.show()\n",
       "\n",
       "    return total_revenue, top_product, top_date\n",
       "\n",
       "file_path = 'sales.csv'\n",
       "total_revenue, top_product, top_date = analyze_sales(file_path)\n",
       "print(f'Total Revenue: {total_revenue}')\n",
       "print(f'Product with Highest Revenue: {top_product}')\n",
       "print(f'Date with Highest Revenue: {top_date}')\n",
       "```\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Get the selected model\n",
    "selected_model = model_selector.get_model_id()\n",
    "model_info = model_selector.get_model_info()\n",
    "\n",
    "print(f\"üîß Generating Python code using: {model_info['name']}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Create messages\n",
    "messages = create_messages(prompt_data)\n",
    "\n",
    "# Generate code\n",
    "response = bedrock.converse(\n",
    "    model_id=selected_model,\n",
    "    messages=messages,\n",
    "    max_tokens=4096,\n",
    "    temperature=0.1,\n",
    "    top_p=0.99\n",
    ")\n",
    "\n",
    "if response:\n",
    "    print(\"üìã Generated Python Code:\")\n",
    "    display(Markdown(f\"```python\\n{response}\\n```\"))\n",
    "else:\n",
    "    print(\"‚ùå Failed to generate code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd05559",
   "metadata": {},
   "source": [
    "#### (Optional) Execute the Bedrock generated code for validation\n",
    "\n",
    "Copy the generated code from above and paste it in the cell below to test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f9165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Revenue: 35490.0\n",
      "Product with Highest Revenue: P003\n",
      "Date with Highest Revenue: 2023-04-23\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def analyze_sales(file_path):\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "\n",
    "    total_revenue = sum(float(row['price']) * int(row['units_sold']) for row in data)\n",
    "    \n",
    "    product_revenue = defaultdict(float)\n",
    "    date_revenue = defaultdict(float)\n",
    "    monthly_sales = defaultdict(float)\n",
    "\n",
    "    for row in data:\n",
    "        revenue = float(row['price']) * int(row['units_sold'])\n",
    "        product_revenue[row['product_id']] += revenue\n",
    "        date_revenue[row['date']] += revenue\n",
    "        month = datetime.strptime(row['date'], '%Y-%m-%d').strftime('%Y-%m')\n",
    "        monthly_sales[month] += revenue\n",
    "\n",
    "    top_product = max(product_revenue, key=product_revenue.get)\n",
    "    top_date = max(date_revenue, key=date_revenue.get)\n",
    "\n",
    "    months = sorted(monthly_sales.keys())\n",
    "    sales = [monthly_sales[month] for month in months]\n",
    "\n",
    "    plt.bar(months, sales)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Monthly Sales')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    return total_revenue, top_product, top_date\n",
    "\n",
    "file_path = 'sales.csv'\n",
    "total_revenue, top_product, top_date = analyze_sales(file_path)\n",
    "print(f'Total Revenue: {total_revenue}')\n",
    "print(f'Product with Highest Revenue: {top_product}')\n",
    "print(f'Date with Highest Revenue: {top_date}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a705e36",
   "metadata": {},
   "source": [
    "### Use case 2 - SQL query generation\n",
    "\n",
    "In this section we show you how to use a LLM to generate SQL queries to analyze Sales data. We will use Amazon Nova Pro model using the Boto3 API. \n",
    "\n",
    "The prompt used in this example is called a zero-shot prompt because we are not providing any examples of text other than the prompt.\n",
    "\n",
    "##### Pattern\n",
    "We will simply provide the Amazon Bedrock API with an input consisting of a task, an instruction and an input for the model to generate an output without providing any additional examples. The purpose here is to demonstrate how the powerful LLMs easily understand the task at hand and generate compelling outputs.\n",
    "\n",
    "##### Use case\n",
    "Let's take the use case to generate SQL queries to analyze sales data, focusing on top products and average monthly sales.\n",
    "\n",
    "##### Persona\n",
    "Maya is a business analyst, at AnyCompany primarily focusing on sales and inventory data. She is transitioning from Speadsheet analysis to data-driven analysis and want to use SQL to fetch specific data points effectively. She wants to use LLMs to generate SQL queries for her analysis. \n",
    "\n",
    "##### Implementation\n",
    "To fulfill this use case, in this notebook we will show how to generate SQL queries. We will use the Amazon Nova Pro model using the Amazon Bedrock API with Boto3 client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902aab8b",
   "metadata": {},
   "source": [
    "#### Generate SQL Query\n",
    "\n",
    "Following on the use case explained above, let's prepare an input for  the Amazon Bedrock service to generate some SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09205c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prompt to generate SQL query\n",
    "prompt_data = \"\"\"\n",
    "AnyCompany has a database with a table named sales_data containing sales records. The table has following columns:\n",
    "- date (YYYY-MM-DD)\n",
    "- product_id\n",
    "- price\n",
    "- units_sold\n",
    "\n",
    "Can you generate SQL queries for the below: \n",
    "- Identify the top 5 best selling products by total sales for the year 2023\n",
    "- Calculate the average of total monthly sales for the year 2023\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae67a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÑÔ∏è Generating SQL queries using: Nova Pro\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìä Generated SQL Queries:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! Below are the SQL queries to achieve the specified tasks:\n",
       "\n",
       "### 1. Identify the Top 5 Best Selling Products by Total Sales for the Year 2023\n",
       "\n",
       "```sql\n",
       "SELECT \n",
       "    product_id,\n",
       "    SUM(price * units_sold) AS total_sales\n",
       "FROM \n",
       "    sales_data\n",
       "WHERE \n",
       "    date BETWEEN '2023-01-01' AND '2023-12-31'\n",
       "GROUP BY \n",
       "    product_id\n",
       "ORDER BY \n",
       "    total_sales DESC\n",
       "LIMIT 5;\n",
       "```\n",
       "\n",
       "### 2. Calculate the Average of Total Monthly Sales for the Year 2023\n",
       "\n",
       "```sql\n",
       "WITH monthly_sales AS (\n",
       "    SELECT \n",
       "        DATE_FORMAT(date, '%Y-%m') AS month,\n",
       "        SUM(price * units_sold) AS total_sales\n",
       "    FROM \n",
       "        sales_data\n",
       "    WHERE \n",
       "        date BETWEEN '2023-01-01' AND '2023-12-31'\n",
       "    GROUP BY \n",
       "        month\n",
       ")\n",
       "SELECT \n",
       "    AVG(total_sales) AS average_monthly_sales\n",
       "FROM \n",
       "    monthly_sales;\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "\n",
       "1. **Top 5 Best Selling Products Query:**\n",
       "   - Filters records for the year 2023 using the `WHERE` clause.\n",
       "   - Groups the results by `product_id`.\n",
       "   - Calculates the total sales for each product using `SUM(price * units_sold)`.\n",
       "   - Orders the results in descending order by total sales.\n",
       "   - Limits the results to the top 5 products.\n",
       "\n",
       "2. **Average Monthly Sales Query:**\n",
       "   - Uses a Common Table Expression (CTE) named `monthly_sales` to:\n",
       "     - Format the `date` to extract the year and month.\n",
       "     - Calculate the total sales for each month.\n",
       "   - Calculates the average of the `total_sales` from the CTE."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Get the selected model\n",
    "selected_model = model_selector.get_model_id()\n",
    "model_info = model_selector.get_model_info()\n",
    "\n",
    "print(f\"üóÑÔ∏è Generating SQL queries using: {model_info['name']}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Create messages\n",
    "messages = create_messages(prompt_data)\n",
    "\n",
    "# Generate SQL using unified Converse API\n",
    "response = bedrock.converse(\n",
    "    model_id=selected_model,\n",
    "    messages=messages,\n",
    "    max_tokens=4096,\n",
    "    temperature=0.1,\n",
    "    top_p=0.99\n",
    ")\n",
    "\n",
    "if response:\n",
    "    print(\"üìä Generated SQL Queries:\")\n",
    "    display(Markdown(response))\n",
    "else:\n",
    "    print(\"‚ùå Failed to generate SQL queries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3660c4c",
   "metadata": {},
   "source": [
    "### Conclusion on Code Generation\n",
    "You have now experimented with using `boto3` SDK which provides a vanilla exposure to Amazon Bedrock API. Using this API you generate a python program to analyze and visualize given sales data, and generate SQL statements based on an input task and schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1e937",
   "metadata": {},
   "source": [
    "## 3. Entity Extraction: Extract structured information from unstructured text\n",
    "\n",
    "### Context\n",
    "Entity extraction is an NLP technique that allows us to automatically extract specific data from naturally written text, such as news, emails, books, etc.\n",
    "That data can then later be saved to a database, used for lookup or any other type of processing.\n",
    "\n",
    "Classic entity extraction programs usually limit you to pre-defined classes, such as name, address, price, etc. or require you to provide many examples of types of entities you are interested in.\n",
    "By using a LLM for entity extraction, in most cases you are only required to specify what you need to extract in natural language. This gives you flexibility and accuracy in your queries, while saving time by removing the need for data labeling.\n",
    "\n",
    "In addition, LLM entity extraction can be used to help you assemble a dataset to create a customised solution for your use case, such as [Amazon Comprehend custom entity](https://docs.aws.amazon.com/comprehend/latest/dg/custom-entity-recognition.html) recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec77dfc",
   "metadata": {},
   "source": [
    "### Entity Extraction\n",
    "\n",
    "For this exercise we will pretend to be an online bookstore that receives questions and orders by email.\n",
    "Our task is to extract relevant information from the email to process the order.\n",
    "\n",
    "Let's begin by taking a look at the sample email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a3a618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sir or Madam,\n",
      "\n",
      "I would like to order Treasure Island, do you have it in stock?\n",
      "\n",
      "Also, is it possible to pay by cheque?\n",
      "\n",
      "Yours sincerely,\n",
      "John Smith\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "emails_dir = Path(\".\") / \"emails\"\n",
    "with open(emails_dir / \"00_treasure_island.txt\") as f:\n",
    "    book_question_email = f.read()\n",
    "\n",
    "print(book_question_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd6c28",
   "metadata": {},
   "source": [
    "### Basic approach\n",
    "\n",
    "First, let's define a function to process queries using our selected model. In the below, we use a system prompt to tell the\n",
    "LLM to act as a bookstore assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f5424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookstore_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Process bookstore queries using the unified Converse API with the selected model.\n",
    "    \"\"\"\n",
    "    # Get the selected model\n",
    "    selected_model = model_selector.get_model_id()\n",
    "    \n",
    "    # Create messages - just the user message\n",
    "    messages = create_messages(query)\n",
    "    \n",
    "    # Use unified Converse API with system message parameter\n",
    "    response = bedrock.converse(\n",
    "        model_id=selected_model,\n",
    "        messages=messages,\n",
    "        max_tokens=4096,\n",
    "        temperature=0.1,\n",
    "        top_p=0.99\n",
    "    )\n",
    "    \n",
    "    return response if response else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f7ec0",
   "metadata": {},
   "source": [
    "For basic cases we can directly ask the model to return the result. Let's try extracting the name of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698e5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "Given the email inside triple-backticks, please read it and analyse the contents.\n",
    "If a name of a book is mentioned, return it, otherwise return nothing.\n",
    "\n",
    "Email: ```\n",
    "{book_question_email}\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b807c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the book mentioned in the email is \"Treasure Island.\"\n"
     ]
    }
   ],
   "source": [
    "result = bookstore_assistant(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de0e9d1",
   "metadata": {},
   "source": [
    "### Model specific prompts\n",
    "\n",
    "While basic approach works, to achieve best results we recommend to apply prompt engineering approaches according to the best practices of the used model e.g. [Amazon Nova's prompting best practices](https://docs.aws.amazon.com/nova/latest/userguide/prompting.html), or [Anthropic's prompt engineering](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/).\n",
    "\n",
    "Here is an example prompt for Anthropic's recommendation to [use XML tags](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e4f602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Given the email provided, please read it and analyse the contents.\n",
    "If a name of a book is mentioned, return it.\n",
    "If no name is mentioned, return empty string.\n",
    "The email will be given between <email></email> XML tags.\n",
    "\n",
    "<email>\n",
    "{email}\n",
    "</email>\n",
    "\n",
    "Return the name of the book between <book></book> XML tags.\n",
    "\n",
    "\"\"\"\n",
    "query = prompt.format(email=book_question_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "601ffe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<book>Treasure Island</book>\n"
     ]
    }
   ],
   "source": [
    "result = bookstore_assistant(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c54a32",
   "metadata": {},
   "source": [
    "To extract results easier, we can use a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "780e3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_by_tag(response: str, tag: str, extract_all=False) -> str | list[str] | None:\n",
    "    soup = BeautifulSoup(response)\n",
    "    results = soup.find_all(tag)\n",
    "    if not results:\n",
    "        return\n",
    "        \n",
    "    texts = [res.get_text() for res in results]\n",
    "    if extract_all:\n",
    "        return texts\n",
    "    return texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c64bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Treasure Island'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_by_tag(result, \"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea235a81",
   "metadata": {},
   "source": [
    "We can check that our model doesn't return arbitrary results when no appropriate information is given (also know as 'hallucination'), by running our prompt on other emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57079295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't like the last book I ordered and would like to return it.\n"
     ]
    }
   ],
   "source": [
    "with open(emails_dir / \"01_return.txt\") as f:\n",
    "    return_email = f.read()\n",
    "\n",
    "print(return_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4611536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<book></book>\n",
      "\n",
      "The email mentions \"the last book I ordered\" but does not provide a specific name for the book. Therefore, the name of the book is not mentioned, and the result is an empty string within the <book></book> tags.\n"
     ]
    }
   ],
   "source": [
    "query = prompt.format(email=return_email)\n",
    "result = bookstore_assistant(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e88bb4",
   "metadata": {},
   "source": [
    "Using tags also allows us to extract multiple pieces of information at the same time and makes extraction much easier.\n",
    "In the following prompt we will extract not just the book name, but any questions, requests and customer name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4c464d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Given email provided , please read it and analyse the contents.\n",
    "\n",
    "Please extract the following information from the email:\n",
    "- Any questions the customer is asking, return it inside <questions></questions> XML tags.\n",
    "- The customer's full name, return it inside <name></name> XML tags.\n",
    "- Any book names the customer mentions, return it inside <books></books> XML tags.\n",
    "\n",
    "If a particular bit of information is not present, return an empty string.\n",
    "Make sure that each question can be understoon by itself, incorporate context if requred.\n",
    "Each returned question should be concise, remove extra information if possible.\n",
    "The email will be given between <email></email> XML tags.\n",
    "\n",
    "<email>\n",
    "{email}\n",
    "</email>\n",
    "\n",
    "Return each question inside <question></question> XML tags.\n",
    "Return the name of each book inside <book></book> XML tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb28d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```xml\n",
      "<questions>\n",
      "    <question>Do you have Treasure Island in stock?</question>\n",
      "    <question>Is it possible to pay by cheque?</question>\n",
      "</questions>\n",
      "<name>John Smith</name>\n",
      "<books>\n",
      "    <book>Treasure Island</book>\n",
      "</books>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = prompt.format(email=book_question_email)\n",
    "result = bookstore_assistant(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca77fdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do you have Treasure Island in stock?', 'Is it possible to pay by cheque?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_by_tag(result, \"question\", extract_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d5e46ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Smith'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_by_tag(result, \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a012b372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Treasure Island']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_by_tag(result, \"book\", extract_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd881de",
   "metadata": {},
   "source": [
    "### Conclusion on Entity Extraction\n",
    "\n",
    "Entity extraction is a powerful technique which can extract arbitrary data from plain text descriptions.\n",
    "\n",
    "This is particularly useful when you need to extract specific data which doesn't have clear structure. In such cases regex and other traditional extraction techniques can be very difficult to implement.\n",
    "\n",
    "### Additional challenges\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Apply different prompt engineering principles to get better outputs. Refer to the prompt guide for your chosen model for recommendations, e.g. [here is the prompt guide for Claude](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b569aa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored text generation capabilities with Amazon Bedrock for the following use cases:\n",
    "\n",
    "1. **Text Summarization**: Create concise summaries from longer text passages\n",
    "2. **Code Generation**: Generate Python and SQL code from natural language descriptions\n",
    "3. **Entity Extraction**: Extract structured information from unstructured text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
